{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fU1jtZhK2xF5"
   },
   "outputs": [],
   "source": [
    "from HestonFFT import Call_Heston\n",
    "import numpy as np \n",
    "import scipy \n",
    "import math\n",
    "import scipy.integrate\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ModelLarge import ModelLarge\n",
    "from TestPerformance import test_performanceNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eUwLlTpN28Gd"
   },
   "outputs": [],
   "source": [
    "#loading the training set\n",
    "df = pd.read_csv(\"HestonTrainXXL.csv\").to_numpy()[:,1:]\n",
    "y = df[:,0].reshape(-1,1)\n",
    "x = df[:,1:]\n",
    "train_x = torch.from_numpy(x).double()\n",
    "train_y = torch.from_numpy(y).reshape(-1,1).double() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BRMqsiJk2_4F"
   },
   "outputs": [],
   "source": [
    "#setting the hyperparameters of the model \n",
    "input_dim = 8\n",
    "hidden_dim = 128\n",
    "\n",
    "model = ModelLarge(input_dim, hidden_dim).to(device)\n",
    "model = model.double()\n",
    "\n",
    "#loss and learning rate \n",
    "criterion = nn.L1Loss()\n",
    "learning_rate = 0.001\n",
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr = learning_rate) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            optimizer, factor=0.5, \n",
    "                            patience=3, \n",
    "                            verbose=True ) \n",
    "\n",
    "\n",
    "#valutation set \n",
    "df = pd.read_csv(\"HestonTestNN.csv\").to_numpy()[:,1:]\n",
    "test_x = df[:,1:]\n",
    "test_y = df[:,0]\n",
    "test_y_Tensor = torch.from_numpy(test_y).to(device)\n",
    "test_x_Tensor = torch.from_numpy(test_x).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nToy63OT3Eih",
    "outputId": "bac4c0c6-4da2-4195-a47b-fbb654a0542f"
   },
   "outputs": [],
   "source": [
    "train = False\n",
    "if train: \n",
    "    num_epochs = 300\n",
    "    iter = 0\n",
    "    N = train_x.shape[0]\n",
    "    batch = 100\n",
    "\n",
    "    train_x = train_x.to(device)\n",
    "    train_y = train_y.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        index = torch.randperm(N)\n",
    "        train_input_shuffled = train_x[index]\n",
    "        train_target_shuffled = train_y[index]\n",
    "        s = 0\n",
    "\n",
    "        for b in range(0, N, batch):\n",
    "            x = train_x.narrow(0, b, batch)\n",
    "            y = train_y.narrow(0, b, batch)\n",
    "\n",
    "            # Clear gradients w.r.t. parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model(x)\n",
    "            # print(y, outputs)\n",
    "            # Calculate Loss:\n",
    "            loss = criterion(outputs, y)\n",
    "            # print(loss)\n",
    "            s += loss\n",
    "\n",
    "            # Getting gradients w.r.t. parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            iter += 1\n",
    "        if epoch % 2 == 0:\n",
    "            test = f\"Test Loss:  {test_performanceNN(test_x_Tensor , test_y_Tensor , model):.2e}\"\n",
    "            print(f\"Epoch: {epoch}    Loss: {s.mean()}    {test}\")\n",
    "        # scheduler wll reduce the learning rate if gor 5 epoch there is no gain in term of the loss\n",
    "        scheduler.step(s.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jVubvpWvvl74"
   },
   "outputs": [],
   "source": [
    "#saving the model\n",
    "#torch.save(model, \"modelNNLarge.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HestonTrainXXL.csv\n",
      "Time:  2.792698621749878\n",
      "AAE:  5.03e-05\n",
      "MAE:  2.21e-03\n",
      "\n",
      "\n",
      "HestonTestS.csv\n",
      "Time:  0.014949798583984375\n",
      "AAE:  6.09e-05\n",
      "MAE:  1.46e-03\n",
      "\n",
      "\n",
      "HestonTestM.csv\n",
      "Time:  0.03089594841003418\n",
      "AAE:  5.69e-05\n",
      "MAE:  8.60e-04\n",
      "\n",
      "\n",
      "HestonTestL.csv\n",
      "Time:  0.08970069885253906\n",
      "AAE:  5.28e-05\n",
      "MAE:  9.55e-04\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loading the model trained on 1milion observations  and look at the performance +\n",
    "mod = torch.load(\"modelNNLarge.pt\")\n",
    "\n",
    "datasets = [\"HestonTrainXXL.csv\", \"HestonTestS.csv\", \"HestonTestM.csv\", \"HestonTestL.csv\"]\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    df = pd.read_csv(dataset).to_numpy()[:,1:]\n",
    "    X = df[:,1:]\n",
    "    y = df[:,0]\n",
    "    test_y_Tensor = torch.from_numpy(y).to(device)\n",
    "    test_x_Tensor = torch.from_numpy(X).to(device)\n",
    "    test_performanceNN(test_x_Tensor, test_y_Tensor, mod, type_ = \"both\", to_return = False, time_ = True)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HestonTrainXL.csv\n",
      "Time:  0.24553990364074707\n",
      "AAE:  1.56e-04\n",
      "MAE:  1.94e-03\n",
      "\n",
      "\n",
      "HestonTestS.csv\n",
      "Time:  0.009966611862182617\n",
      "AAE:  1.78e-04\n",
      "MAE:  2.34e-03\n",
      "\n",
      "\n",
      "HestonTestM.csv\n",
      "Time:  0.032892465591430664\n",
      "AAE:  1.76e-04\n",
      "MAE:  1.34e-03\n",
      "\n",
      "\n",
      "HestonTestL.csv\n",
      "Time:  0.052826642990112305\n",
      "AAE:  1.71e-04\n",
      "MAE:  2.67e-03\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#loading the model trained on 100k observations  and look at the performance +\n",
    "mod = torch.load(\"modelNNLarge_SmallTrain.pt\")\n",
    "\n",
    "datasets = [\"HestonTrainXL.csv\", \"HestonTestS.csv\", \"HestonTestM.csv\", \"HestonTestL.csv\"]\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    df = pd.read_csv(dataset).to_numpy()[:,1:]\n",
    "    X = df[:,1:]\n",
    "    y = df[:,0]\n",
    "    test_y_Tensor = torch.from_numpy(y).to(device)\n",
    "    test_x_Tensor = torch.from_numpy(X).to(device)\n",
    "    test_performanceNN(test_x_Tensor, test_y_Tensor, mod, type_ = \"both\", to_return = False, time_ = True)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
